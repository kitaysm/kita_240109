{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoqsqWOWx1zQ","executionInfo":{"status":"ok","timestamp":1709510738590,"user_tz":-540,"elapsed":19402,"user":{"displayName":"윤성민","userId":"16811637789562166726"}},"outputId":"4625a605-d0a6-4395-a5c5-7670b29be948"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"YixrCxo8O8N_"},"source":["TPU 이외에 의존성 있는 패키지를 설치합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9872,"status":"ok","timestamp":1709511231581,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"0U3MeuPe4HkP","outputId":"a7c01ca6-aebe-4330-da44-95e94ab56d9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ratsnlp in /usr/local/lib/python3.10/dist-packages (1.0.53)\n","Requirement already satisfied: pytorch-lightning==1.6.1 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (1.6.1)\n","Requirement already satisfied: transformers==4.28.1 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (4.28.1)\n","Requirement already satisfied: Korpora>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (0.2.0)\n","Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (2.2.5)\n","Requirement already satisfied: flask-ngrok>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (0.0.25)\n","Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (4.0.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.25.2)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2.1.0+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (6.0.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2023.6.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2.15.2)\n","Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (0.3.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (0.20.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (0.13.3)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (8.1.7)\n","Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.10/dist-packages (from Korpora>=0.2.0->ratsnlp) (0.6)\n","Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (3.9.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=1.1.4->ratsnlp) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (2024.2.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.62.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.5.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.7.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (3.2.1)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (2.1.0)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.4.1->pytorch-lightning==1.6.1->ratsnlp) (0.10.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.2.2)\n"]}],"source":["!pip install ratsnlp"]},{"cell_type":"markdown","metadata":{"id":"Skjaa0Gk6d_X"},"source":["# 구글 드라이브 연동하기\n","모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4161,"status":"ok","timestamp":1709511251973,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"QQCGKzLXJuED","outputId":"2d7611d4-65c6-43a1-8dc1-b9ee2e3572f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"ML-ubp246uzI"},"source":["# 각종 설정\n","모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"dtoPBSH4v31j","executionInfo":{"status":"ok","timestamp":1709511351905,"user_tz":-540,"elapsed":8898,"user":{"displayName":"윤성민","userId":"16811637789562166726"}}},"outputs":[],"source":["import torch\n","from ratsnlp.nlpbook.qa import QATrainArguments\n","args = QATrainArguments(\n","    pretrained_model_name=\"beomi/kcbert-large\",\n","    downstream_corpus_name=\"korquad-v1\",\n","    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-qa\",\n","    max_seq_length=128, # 질문 + 지문\n","    max_query_length=32, # 질문\n","    doc_stride=64,\n","    batch_size=32 if torch.cuda.is_available() else 4,\n","    learning_rate=5e-5,\n","    epochs=3,\n","    tpu_cores=0 if torch.cuda.is_available() else 8,\n","    seed=7,\n",")"]},{"cell_type":"markdown","metadata":{"id":"48RjaTAr7D4M"},"source":["# 랜덤 시드 고정\n","학습 재현을 위해 랜덤 시드를 고정합니다."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1709512006274,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"HuacSUSd7JRf","outputId":"f5f6fadb-bfdf-48cb-b1b8-273b6d26a46e"},"outputs":[{"output_type":"stream","name":"stdout","text":["set seed: 7\n"]}],"source":["from ratsnlp import nlpbook\n","nlpbook.set_seed(args)"]},{"cell_type":"markdown","metadata":{"id":"FeTvf0bc9bbV"},"source":["# 로거 설정\n","메세지 출력 등을 위한 logger를 설정합니다."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1709512008178,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"251gdehZ9iPZ","outputId":"b4af82d0-b268-4b38-bd86-85c87fc07223"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:ratsnlp:Training/evaluation parameters QATrainArguments(pretrained_model_name='beomi/kcbert-large', downstream_corpus_name='korquad-v1', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-qa', max_seq_length=128, doc_stride=64, max_query_length=32, threads=4, cpu_workers=2, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, fp16=False, tpu_cores=0, tqdm_enabled=True)\n","INFO:ratsnlp:Training/evaluation parameters QATrainArguments(pretrained_model_name='beomi/kcbert-large', downstream_corpus_name='korquad-v1', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-qa', max_seq_length=128, doc_stride=64, max_query_length=32, threads=4, cpu_workers=2, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, fp16=False, tpu_cores=0, tqdm_enabled=True)\n"]}],"source":["nlpbook.set_logger(args)"]},{"cell_type":"markdown","metadata":{"id":"DqUazvWL7Pry"},"source":["# 말뭉치 다운로드\n","실습에 사용할 말뭉치(KorQuAD-V1)를 다운로드합니다.\n","\n","https://github.com/ratsgo/ratsnlp/blob/master/ratsnlp/nlpbook/utils.py"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2711,"status":"ok","timestamp":1709512018259,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"opyaJgPA7Zxi","outputId":"3cb013dc-bfe3-48a0-b329-18774e6cf4ec"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: 38.5MB [00:00, 60.0MB/s]\n","Downloading: 3.88MB [00:00, 44.4MB/s]                  \n"]}],"source":["nlpbook.download_downstream_dataset(args)"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Q5o3XBn3xfz","executionInfo":{"status":"ok","timestamp":1709512274990,"user_tz":-540,"elapsed":3,"user":{"displayName":"윤성민","userId":"16811637789562166726"}},"outputId":"dbd8c1ae-6856-4d5c-b6db-151fe6d157ae"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  Korpora\tsample_data\n"]}]},{"cell_type":"code","source":["import json\n","with open('/content/Korpora/korquad-v1/KorQuAD_v1.0_train.json', 'r') as f:\n","  train_data = json.load(f)\n","train_data = [item for topic in train_data['data'] for item in topic['paragraphs']]\n","print(len(train_data))\n","train_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnRvoPUF4Vu-","executionInfo":{"status":"ok","timestamp":1709512603312,"user_tz":-540,"elapsed":1477,"user":{"displayName":"윤성민","userId":"16811637789562166726"}},"outputId":"725bcad9-3e2c-4600-8465-4e13d4b365a8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["9681\n"]},{"output_type":"execute_result","data":{"text/plain":["{'qas': [{'answers': [{'text': '교향곡', 'answer_start': 54}],\n","   'id': '6566495-0-0',\n","   'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?'},\n","  {'answers': [{'text': '1악장', 'answer_start': 421}],\n","   'id': '6566495-0-1',\n","   'question': '바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?'},\n","  {'answers': [{'text': '베토벤의 교향곡 9번', 'answer_start': 194}],\n","   'id': '6566495-0-2',\n","   'question': '바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?'},\n","  {'answers': [{'text': '파우스트', 'answer_start': 15}],\n","   'id': '6566518-0-0',\n","   'question': '1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?'},\n","  {'answers': [{'text': '합창교향곡', 'answer_start': 354}],\n","   'id': '6566518-0-1',\n","   'question': '파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?'},\n","  {'answers': [{'text': '1839', 'answer_start': 0}],\n","   'id': '5917067-0-0',\n","   'question': '바그너가 파우스트를 처음으로 읽은 년도는?'},\n","  {'answers': [{'text': '파리', 'answer_start': 410}],\n","   'id': '5917067-0-1',\n","   'question': '바그너가 처음 교향곡 작곡을 한 장소는?'},\n","  {'answers': [{'text': '드레스덴', 'answer_start': 534}],\n","   'id': '5917067-0-2',\n","   'question': '바그너의 1악장의 초연은 어디서 연주되었는가?'}],\n"," 'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import json\n","with open('/content/Korpora/korquad-v1/KorQuAD_v1.0_dev.json', 'r') as f:\n","  train_data = json.load(f)\n","train_data = [item for topic in train_data['data'] for item in topic['paragraphs']]\n","print(len(train_data))\n","train_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fERMrpxj5Ei_","executionInfo":{"status":"ok","timestamp":1709512691200,"user_tz":-540,"elapsed":341,"user":{"displayName":"윤성민","userId":"16811637789562166726"}},"outputId":"b6736a53-6912-424c-953a-a0e8a00e1058"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["964\n"]},{"output_type":"execute_result","data":{"text/plain":["{'qas': [{'answers': [{'text': '1989년 2월 15일', 'answer_start': 0}],\n","   'id': '6548850-0-0',\n","   'question': '임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?'},\n","  {'answers': [{'text': '임수경', 'answer_start': 125}],\n","   'id': '6548850-0-1',\n","   'question': '1989년 6월 30일 평양축전에 대표로 파견 된 인물은?'},\n","  {'answers': [{'text': '1989년', 'answer_start': 0}],\n","   'id': '6548853-0-0',\n","   'question': '임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?'},\n","  {'answers': [{'text': '학생회관 건물 계단', 'answer_start': 365}],\n","   'id': '6548853-0-1',\n","   'question': '임종석을 검거한 장소는 경희대 내 어디인가?'},\n","  {'answers': [{'text': '서울지방경찰청 공안분실', 'answer_start': 457}],\n","   'id': '6548853-0-2',\n","   'question': '임종석이 조사를 받은 뒤 인계된 곳은 어딘가?'},\n","  {'answers': [{'text': '임종석', 'answer_start': 87}],\n","   'id': '6332405-0-0',\n","   'question': '1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?'},\n","  {'answers': [{'text': '여의도 농민 폭력 시위', 'answer_start': 13}],\n","   'id': '6332405-0-1',\n","   'question': '임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?'}],\n"," 'context': '1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.'}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"2DnwLCKB7cRq"},"source":["# 토크나이저 준비\n","토큰화를 수행하는 토크나이저를 선언합니다"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223,"referenced_widgets":["577786c1d960481e97a39178cb102a33","0427bd7780a34f36a2452ad52adc1489","901701db66a246fea8d0429309ae1f1a","ee10578102904375b245180d23588a19","00868f0be51043b5b78ee0d45e68afa0","509947fcd559409db4599fcf29019b18","fa733a9a3bf34006b59b7905d38ca7ea","e3be128a9ace40a0978275d1b43b67e1","54a8b85a776343abac7eda5459875878","2d27c119962e45798a6133287ace92e3","016dd177f1ab4512b645bb2bc8501210","7a50e69c19e64277a0baeef445e8939e","0e5bb20d71234d059176a9bcafc80d7c","defc321c3eb2479687ab39566f2c223a","36a24781117c45d4981edc18143f9599","5eaf804996cf4748ad3049f32b36b3b7","e03e48c52cab47c4b1d78cd6667bfc6b","54ffb8bd36c74ad6b8748524e3772a28","93f3eb2be2b940ebab84796f244206b1","d308d42d1c8c426297b39e4540764f3f","10492bdd62504bada9b0ca9285aaf1be","5cec4d0cec664c6cb28a326a7774591f","eaf3de3974dd43859a452529a687033f","53a4279e6a2d4876a10e29156effc4a4","7fbd55417d254c4594d02cc52d0017e2","ac465586f82e4e299b93bb3439fed12c","07f638643b4944339408ff58c940eba4","93328b160b0c43b1a66d3a4fdc97971b","fa680e4874a34281b70d42fa7d91a958","7f0c9f18dc804b13ba216ff105119839","3a35fa00466845f38234a62dfff2536a","638c8fb7b00f4f968ccbd07e73bbc44d","545e4b996df1485bbc3436fea1747ff6"]},"executionInfo":{"elapsed":2549,"status":"ok","timestamp":1709513544170,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"OlcoBivi7hIY","outputId":"caa14073-040b-48b4-b417-2ef96b1d986b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"577786c1d960481e97a39178cb102a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a50e69c19e64277a0baeef445e8939e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/672 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaf3de3974dd43859a452529a687033f"}},"metadata":{}}],"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained(\n","    args.pretrained_model_name,\n","    do_lower_case=False,\n",")"]},{"cell_type":"markdown","metadata":{"id":"hZbLCM5e7i6g"},"source":["# 학습데이터 구축\n","학습데이터를 만듭니다.\n","\n","https://github.com/ratsgo/ratsnlp/blob/master/ratsnlp/nlpbook/qa/corpus.py"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":348418,"status":"ok","timestamp":1709513897029,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"v9s8znA17ovP","outputId":"7e093d3d-b70b-4c2e-9d22-ad909ef0c98a"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:ratsnlp:Creating features from train dataset file at /content/Korpora/korquad-v1\n","INFO:ratsnlp:Creating features from train dataset file at /content/Korpora/korquad-v1\n","100%|██████████| 1420/1420 [00:00<00:00, 20099.66it/s]\n","convert squad examples to features: 100%|██████████| 57688/57688 [05:10<00:00, 185.66it/s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:answer: 교 ##향 ##곡\n","INFO:ratsnlp:answer: 교 ##향 ##곡\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=45, end_positions=47)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=45, end_positions=47)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=108, end_positions=110)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=108, end_positions=110)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=44, end_positions=46)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=44, end_positions=46)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question & context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_train_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 36.205 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_train_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 36.205 s]\n"]}],"source":["from ratsnlp.nlpbook.qa import KorQuADV1Corpus, QADataset\n","from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n","corpus = KorQuADV1Corpus()\n","train_dataset = QADataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"train\",\n",")\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    sampler=RandomSampler(train_dataset, replacement=False),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")"]},{"cell_type":"markdown","metadata":{"id":"SOAACuBY7vem"},"source":["# 테스트 데이터 구축\n","학습 중에 평가할 테스트 데이터를 구축합니다."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55797,"status":"ok","timestamp":1709514678030,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"mcm1tgfq7y84","outputId":"b171c312-ea36-4218-8fd6-836bd50e4e86"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:ratsnlp:Creating features from val dataset file at /content/Korpora/korquad-v1\n","INFO:ratsnlp:Creating features from val dataset file at /content/Korpora/korquad-v1\n","100%|██████████| 140/140 [00:00<00:00, 8888.25it/s]\n","convert squad examples to features: 100%|██████████| 5533/5533 [00:45<00:00, 121.07it/s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:answer: 임 ##수 ##경을\n","INFO:ratsnlp:answer: 임 ##수 ##경을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=75, end_positions=77)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=75, end_positions=77)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: 학생 ##회 ##관 건물 계 ##단을\n","INFO:ratsnlp:answer: 학생 ##회 ##관 건물 계 ##단을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=61, end_positions=66)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=61, end_positions=66)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question & context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로\n","INFO:ratsnlp:answer: 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=103, end_positions=110)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=103, end_positions=110)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 사람의 이름은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 [SEP]\n","INFO:ratsnlp:question & context: [CLS] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 사람의 이름은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 [SEP]\n","INFO:ratsnlp:answer: 임종석\n","INFO:ratsnlp:answer: 임종석\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 4091, 23985, 4110, 4200, 4130, 12162, 25542, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=62, end_positions=62)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 4091, 23985, 4110, 4200, 4130, 12162, 25542, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=62, end_positions=62)\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_val_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 7.000 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_val_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 7.000 s]\n"]}],"source":["val_dataset = QADataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"val\",\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    sampler=SequentialSampler(val_dataset),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"HztMCywb70e9"},"source":["# 모델 초기화\n","프리트레인이 완료된 BERT 모델을 읽고, 질의 응답을 수행할 모델을 초기화합니다."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ohOlRdP18GVe","executionInfo":{"status":"ok","timestamp":1709514766260,"user_tz":-540,"elapsed":402,"user":{"displayName":"윤성민","userId":"16811637789562166726"}}},"outputs":[],"source":["from transformers import BertConfig\n","pretrained_model_config = BertConfig.from_pretrained(\n","    args.pretrained_model_name,\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["b2949d2c2fe14716b9496356e7827508","cd1a3ae97e0f4ec795a553bfc84c52f4","9d1721dd0b2342be8753249ae246589e","1092020d69a241a49764777a1e64d6f3","9b5c3fd6f0e64002b996d65d2f1602c6","9e571b1a745948eeb122ea3350ac3173","c9049af59c2340b699892106447492bb","d24c9f8eb7e34a5bbe7746d76bec097f","69c9bc5f07b546b2bf05a0dfdfcec5df","99f9dbad7a7b447b996d60f3ffdee0b6","338dffeb65644c2cb35399e6db160620"]},"executionInfo":{"elapsed":33738,"status":"ok","timestamp":1709514858744,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"staYwMx88MWQ","outputId":"98c88e5e-9491-4d46-944d-85d3ba65cd82"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2949d2c2fe14716b9496356e7827508"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at beomi/kcbert-large were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained(\n","        args.pretrained_model_name,\n","        config=pretrained_model_config,\n",")"]},{"cell_type":"markdown","metadata":{"id":"lYtJXijM8PN8"},"source":["# 학습 준비\n","Task와 Trainer를 준비합니다."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"-FFn4MSz8SWu","executionInfo":{"status":"ok","timestamp":1709515285037,"user_tz":-540,"elapsed":525,"user":{"displayName":"윤성민","userId":"16811637789562166726"}}},"outputs":[],"source":["from ratsnlp.nlpbook.qa import QATask\n","task = QATask(model, args)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1709515287727,"user":{"displayName":"윤성민","userId":"16811637789562166726"},"user_tz":-540},"id":"18W4vRtR8UTx","outputId":"74c62d49-6b56-4398-f396-52b28e8f3537"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}],"source":["trainer = nlpbook.get_trainer(args)"]},{"cell_type":"markdown","metadata":{"id":"KteHdhBT8X0e"},"source":["# 학습\n","준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-qa`)에 저장됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378,"referenced_widgets":["7aabf9485ee44c16b1af9f6209b9781f","6a3025fa43954e5dbec869fb08a056e2","63c2f6d0880b4a3ca93839ff0f5be1cb","6826ee0c614046fa8c92a5d07ee95baa","109ec0b8987d429f8cdb1acccb95bb7b","e7ba5236552b4d829338b87608316cff","85a3fde8f836400f8a9b8313781b3bce","291e3360de0f491e91ba22228e464420","ad7e3757607a4ec5afd014941f86568c","d4b54b05ebec4a5f91158a66ace21d42","09e8ebd5dd0e4e84a2b0ed0ef9a7816a","b4942624bf3b4d31970d247751b9892b","f404919d6f444943a8de9d47defa6c18","b044b25b610446b7a72da83bfdbf031e","c3dec4d253ee43aaa497cc007124eb2d","78c73275c90847a8bb995b4a4ceb81ba","a9e3e23e3c354c0eac79c33cec465213","9d43380133d341ccaea23cd7a9ff1fb6","4fc70ee38a8c41c29f402d8cf01e0fc4","1df9780e4be24f0894977e071c1619f0","32541c8cd9234e96baa2538ad065da5e","f5020d3b65384e2ab70f720cdf608964"]},"id":"SDr3M_nF8l7M","outputId":"6bf7ad0c-4e2c-4c10-b775-66646856b9b4","executionInfo":{"status":"ok","timestamp":1709479027145,"user_tz":-540,"elapsed":5335853,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /gdrive/My Drive/nlpbook/checkpoint-qa1/lightning_logs\n","INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py:380: RuntimeWarning: Found unsupported keys in the optimizer configuration: {'scheduler'}\n","  rank_zero_warn(\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name  | Type                     | Params\n","---------------------------------------------------\n","0 | model | BertForQuestionAnswering | 333 M \n","---------------------------------------------------\n","333 M     Trainable params\n","0         Non-trainable params\n","333 M     Total params\n","1,333.371 Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aabf9485ee44c16b1af9f6209b9781f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4942624bf3b4d31970d247751b9892b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["trainer.fit(\n","    task,\n","    train_dataloaders=train_dataloader,\n","    val_dataloaders=val_dataloader,\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/question_answering/train_colab.ipynb","timestamp":1673052208828}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7aabf9485ee44c16b1af9f6209b9781f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a3025fa43954e5dbec869fb08a056e2","IPY_MODEL_63c2f6d0880b4a3ca93839ff0f5be1cb","IPY_MODEL_6826ee0c614046fa8c92a5d07ee95baa"],"layout":"IPY_MODEL_109ec0b8987d429f8cdb1acccb95bb7b"}},"6a3025fa43954e5dbec869fb08a056e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7ba5236552b4d829338b87608316cff","placeholder":"​","style":"IPY_MODEL_85a3fde8f836400f8a9b8313781b3bce","value":"Epoch 1:  42%"}},"63c2f6d0880b4a3ca93839ff0f5be1cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_291e3360de0f491e91ba22228e464420","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad7e3757607a4ec5afd014941f86568c","value":1}},"6826ee0c614046fa8c92a5d07ee95baa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4b54b05ebec4a5f91158a66ace21d42","placeholder":"​","style":"IPY_MODEL_09e8ebd5dd0e4e84a2b0ed0ef9a7816a","value":" 3200/7688 [1:28:49&lt;2:04:34,  1.67s/it, loss=0.338, v_num=0, acc=0.953, val_loss=0.426, val_acc=0.874]"}},"109ec0b8987d429f8cdb1acccb95bb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e7ba5236552b4d829338b87608316cff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85a3fde8f836400f8a9b8313781b3bce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"291e3360de0f491e91ba22228e464420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7e3757607a4ec5afd014941f86568c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4b54b05ebec4a5f91158a66ace21d42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09e8ebd5dd0e4e84a2b0ed0ef9a7816a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4942624bf3b4d31970d247751b9892b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f404919d6f444943a8de9d47defa6c18","IPY_MODEL_b044b25b610446b7a72da83bfdbf031e","IPY_MODEL_c3dec4d253ee43aaa497cc007124eb2d"],"layout":"IPY_MODEL_78c73275c90847a8bb995b4a4ceb81ba"}},"f404919d6f444943a8de9d47defa6c18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9e3e23e3c354c0eac79c33cec465213","placeholder":"​","style":"IPY_MODEL_9d43380133d341ccaea23cd7a9ff1fb6","value":"Validation DataLoader 0: 100%"}},"b044b25b610446b7a72da83bfdbf031e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fc70ee38a8c41c29f402d8cf01e0fc4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1df9780e4be24f0894977e071c1619f0","value":1}},"c3dec4d253ee43aaa497cc007124eb2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32541c8cd9234e96baa2538ad065da5e","placeholder":"​","style":"IPY_MODEL_f5020d3b65384e2ab70f720cdf608964","value":" 691/691 [01:54&lt;00:00,  6.02it/s]"}},"78c73275c90847a8bb995b4a4ceb81ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a9e3e23e3c354c0eac79c33cec465213":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d43380133d341ccaea23cd7a9ff1fb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fc70ee38a8c41c29f402d8cf01e0fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1df9780e4be24f0894977e071c1619f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32541c8cd9234e96baa2538ad065da5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5020d3b65384e2ab70f720cdf608964":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"577786c1d960481e97a39178cb102a33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0427bd7780a34f36a2452ad52adc1489","IPY_MODEL_901701db66a246fea8d0429309ae1f1a","IPY_MODEL_ee10578102904375b245180d23588a19"],"layout":"IPY_MODEL_00868f0be51043b5b78ee0d45e68afa0"}},"0427bd7780a34f36a2452ad52adc1489":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_509947fcd559409db4599fcf29019b18","placeholder":"​","style":"IPY_MODEL_fa733a9a3bf34006b59b7905d38ca7ea","value":"vocab.txt: 100%"}},"901701db66a246fea8d0429309ae1f1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3be128a9ace40a0978275d1b43b67e1","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54a8b85a776343abac7eda5459875878","value":249928}},"ee10578102904375b245180d23588a19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d27c119962e45798a6133287ace92e3","placeholder":"​","style":"IPY_MODEL_016dd177f1ab4512b645bb2bc8501210","value":" 250k/250k [00:00&lt;00:00, 7.51MB/s]"}},"00868f0be51043b5b78ee0d45e68afa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509947fcd559409db4599fcf29019b18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa733a9a3bf34006b59b7905d38ca7ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3be128a9ace40a0978275d1b43b67e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a8b85a776343abac7eda5459875878":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d27c119962e45798a6133287ace92e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"016dd177f1ab4512b645bb2bc8501210":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a50e69c19e64277a0baeef445e8939e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e5bb20d71234d059176a9bcafc80d7c","IPY_MODEL_defc321c3eb2479687ab39566f2c223a","IPY_MODEL_36a24781117c45d4981edc18143f9599"],"layout":"IPY_MODEL_5eaf804996cf4748ad3049f32b36b3b7"}},"0e5bb20d71234d059176a9bcafc80d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e03e48c52cab47c4b1d78cd6667bfc6b","placeholder":"​","style":"IPY_MODEL_54ffb8bd36c74ad6b8748524e3772a28","value":"tokenizer_config.json: 100%"}},"defc321c3eb2479687ab39566f2c223a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f3eb2be2b940ebab84796f244206b1","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d308d42d1c8c426297b39e4540764f3f","value":49}},"36a24781117c45d4981edc18143f9599":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10492bdd62504bada9b0ca9285aaf1be","placeholder":"​","style":"IPY_MODEL_5cec4d0cec664c6cb28a326a7774591f","value":" 49.0/49.0 [00:00&lt;00:00, 3.62kB/s]"}},"5eaf804996cf4748ad3049f32b36b3b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e03e48c52cab47c4b1d78cd6667bfc6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54ffb8bd36c74ad6b8748524e3772a28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93f3eb2be2b940ebab84796f244206b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d308d42d1c8c426297b39e4540764f3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10492bdd62504bada9b0ca9285aaf1be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cec4d0cec664c6cb28a326a7774591f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaf3de3974dd43859a452529a687033f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53a4279e6a2d4876a10e29156effc4a4","IPY_MODEL_7fbd55417d254c4594d02cc52d0017e2","IPY_MODEL_ac465586f82e4e299b93bb3439fed12c"],"layout":"IPY_MODEL_07f638643b4944339408ff58c940eba4"}},"53a4279e6a2d4876a10e29156effc4a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93328b160b0c43b1a66d3a4fdc97971b","placeholder":"​","style":"IPY_MODEL_fa680e4874a34281b70d42fa7d91a958","value":"config.json: 100%"}},"7fbd55417d254c4594d02cc52d0017e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f0c9f18dc804b13ba216ff105119839","max":672,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a35fa00466845f38234a62dfff2536a","value":672}},"ac465586f82e4e299b93bb3439fed12c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_638c8fb7b00f4f968ccbd07e73bbc44d","placeholder":"​","style":"IPY_MODEL_545e4b996df1485bbc3436fea1747ff6","value":" 672/672 [00:00&lt;00:00, 27.3kB/s]"}},"07f638643b4944339408ff58c940eba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93328b160b0c43b1a66d3a4fdc97971b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa680e4874a34281b70d42fa7d91a958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f0c9f18dc804b13ba216ff105119839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a35fa00466845f38234a62dfff2536a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"638c8fb7b00f4f968ccbd07e73bbc44d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"545e4b996df1485bbc3436fea1747ff6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2949d2c2fe14716b9496356e7827508":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd1a3ae97e0f4ec795a553bfc84c52f4","IPY_MODEL_9d1721dd0b2342be8753249ae246589e","IPY_MODEL_1092020d69a241a49764777a1e64d6f3"],"layout":"IPY_MODEL_9b5c3fd6f0e64002b996d65d2f1602c6"}},"cd1a3ae97e0f4ec795a553bfc84c52f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e571b1a745948eeb122ea3350ac3173","placeholder":"​","style":"IPY_MODEL_c9049af59c2340b699892106447492bb","value":"model.safetensors: 100%"}},"9d1721dd0b2342be8753249ae246589e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d24c9f8eb7e34a5bbe7746d76bec097f","max":1341943454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69c9bc5f07b546b2bf05a0dfdfcec5df","value":1341943454}},"1092020d69a241a49764777a1e64d6f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99f9dbad7a7b447b996d60f3ffdee0b6","placeholder":"​","style":"IPY_MODEL_338dffeb65644c2cb35399e6db160620","value":" 1.34G/1.34G [00:27&lt;00:00, 52.8MB/s]"}},"9b5c3fd6f0e64002b996d65d2f1602c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e571b1a745948eeb122ea3350ac3173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9049af59c2340b699892106447492bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d24c9f8eb7e34a5bbe7746d76bec097f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69c9bc5f07b546b2bf05a0dfdfcec5df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99f9dbad7a7b447b996d60f3ffdee0b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"338dffeb65644c2cb35399e6db160620":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}